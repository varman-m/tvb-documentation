{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###Demo use case: showing TVB flexibility. <br>\n", "Set up a complete simulation and analysis  scheme imitating the exploratory workflow in studies from the  literature.<br>\n", "See Fig. 9 in [1]<br>\n", "The underlying idea is is based on [2] and [3] and probably should aim to finally<br>\n", "reproduce [4].<br>\n", "<br>\n", "Background: <br>\n", "    This demo should not be taken as an attempt to reproduce experimental results.<br>\n", "    It lacks from solid theoretical foundations. The background info is only<br>\n", "    to give a more scientifically interesting scenario and justify the choices<br>\n", "    of the observed nodes and such. <br>\n", "    <br>\n", "    When thinking about stimulation paradigms in the context of a whole brain <br>\n", "    experimental protocol, the first ones that jump to my mind: <br>\n", "        - face/object recognition.<br>\n", "        - visually evoked potentials (VEP).<br>\n", "        - trans-cranial magnetic stimulation (TMS).<br>\n", "        <br>\n", "    <br>\n", "    The constraints: <br>\n", "        - Make a demo as simple as possible and thus not including the sub-cortical<br>\n", "          structures. Many sensory inputs go first through the thalamus and then<br>\n", "          its projections reach the cortex. <br>\n", "        - Directly stimulating the cortex with an arbitrary stimulus. Intensity <br>\n", "          units are arbitrary.   <br>\n", "    <br>\n", "    Finally, the stimulus is a Pulse Train with a frequency repetition of 4Hz. <br>\n", "    This low value is the frequency used for flashing stimuli.  Visual stimuli <br>\n", "    stimulate both primary visual and secondary visual areas (V1, V2)<br>\n", "    <br>\n", "    Recordings from scalp: the mid-occipital electrode location (OZ) as in [2] and<br>\n", "    because we are stimulating the visual cortex.  <br>\n", "<br>\n", "Steps: <br>\n", "    1. Set up basic simulation components<br>\n", "    2. Build a stimulation pattern<br>\n", "    3. Generate simulated data with and without stimulation. <br>\n", "    4. Compute MSE<br>\n", "    5. Plot results<br>\n", "<br>\n", "Objective:<br>\n", "   Compare the complexity in the resting state against evoked activity, based<br>\n", "   on MSE computed on the EEG time-series from sensor Oz (occipital region).<br>\n", "   The scientific motivation is (would be) to evaluate how complexity changes as <br>\n", "   a function of stimulation.<br>\n", "<br>\n", "    <br>\n", "Sim Info: <br>\n", "    Node indices corresponding to left  temporal and visual cortices (30:36).<br>\n", "    - assuming the Connectivity matrix is the default with 74 nodes.<br>\n", "<br>\n", "    EEG electrode indice corresponding to O1, O2 and Oz (8, 9, 60).<br>\n", "    The EEG sensors represent 62 scalp electrodes distributed according to the <br>\n", "    10\u201320 system.<br>\n", "<br>\n", "[1] Sanz Leon P.; Woodman; M.; Knock; S.; (...); Jirsa, V. The Virtual Brain: a<br>\n", "    simulator of primate brain dynamics. Frontiers in Neuroinformatics.<br>\n", "<br>\n", "[2] McIntosh, A.; Kovacevic, N.; Lippe, S.; Garrett, D.; Grady, C. & Jirsa, V. <br>\n", "    The Development of a Noisy Brain Archives Italiennes de Biologie, 2010, 148, -<br>\n", "[3] Schneider, G. E. Two visual systems. Science, 1969, 163, 895-902<br>\n", "<br>\n", "Recommended:<br>\n", "<br>\n", "[4] David, O. & Friston, K. J. A neural mass model for MEG/EEG: coupling and <br>\n", "neuronal dynamics. Neuroimage.<br>\n", "<br>\n", "<br>\n", "Total runtime ~ 10 min on Intel Xeon(R) CPU W3520 @ 2.67GHz <br>\n", "<br>\n", "SSVEP: Steady State Visually Evoked Potentials.  There is a number of points to be <br>\n", "determined. Selection of electrodes and stimulating frequencies, feature extraction <br>\n", "(MSE?), spectral methods. Lead position is important, however for VEPs, normally <br>\n", "electrode at the occipital region are selected.<br>\n", "<br>\n", "TCc --> central temporal cortex\t\t\t\t\t\t\t\t<br>\n", "TCi --> inferior temporal cortex\t"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_ipython().magic('pylab inline')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tvb.simulator.lab import *\n", "LOG = get_logger('demo')\n", "import matplotlib.gridspec as gridspec\n", "from tvb.datatypes.projections import ProjectionSurfaceEEG\n", "from tvb.datatypes.sensors import SensorsEEG\n", "from tvb.datatypes.region_mapping import RegionMapping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lV1, lV2,"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nodes = [35, 36]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["O1, O2, Oz"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["eeg_nodes = [8, 9, 60]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["discard transients for analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start = 2048 * 2 - 128  # at 1 second\n", "# for pretty pictures\n", "stop = 2048 * 5 - 64  # 2.5 second"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set up a simulator  instance "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def configure_simulation(stimulate):\n", "    \"\"\"\n", "    Set up a Simulator object (a brain network model and all its individual \n", "    components + output modalities)\n", "    \"\"\"\n", "    # eeg projection matrix from regions to sensors\n", "    LOG.info(\"Reading sensors info\")\n", "    pr = ProjectionSurfaceEEG(load_default=True)\n", "    sensors = SensorsEEG(load_default=True)\n", "    rm = RegionMapping(load_default=True)\n\n", "    #Initialise a Model, Connectivity, Coupling, set speed.\n", "    oscilator = models.Generic2dOscillator(a=-0.5, b=-10., c=0.0, d=0.02)\n", "    white_matter = connectivity.Connectivity(load_default=True)\n", "    white_matter.speed = numpy.array([4.0])\n", "    white_matter_coupling = coupling.Linear(a=0.042)\n\n", "    #Initialise an Integrator\n", "    hiss = noise.Additive(nsig=numpy.array([0.00]))  # nsigm 0.015\n", "    heunint = integrators.HeunStochastic(dt=2 ** -6, noise=hiss)\n\n", "    # Recording techniques\n", "    what_to_watch = (monitors.TemporalAverage(period=1e3 / 4096.),\n", "                     monitors.EEG(projection=pr, sensors=sensors, region_mapping=rm, period=1e3 / 4096.))\n", "    # Stimulation paradigm\n", "    if stimulate:\n", "        stimulus = build_stimulus(white_matter)\n", "    else:\n", "        stimulus = None\n\n", "    #Initialise a Simulator -- Model, Connectivity, Integrator, and Monitors.\n", "    sim = simulator.Simulator(model=oscilator, connectivity=white_matter, coupling=white_matter_coupling,\n", "                              integrator=heunint, monitors=what_to_watch, stimulus=stimulus)\n", "    sim.configure()\n", "    return sim\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_simulation(sim):\n", "    LOG.info(\"Starting simulation...\")\n", "    #Perform the simulation\n", "    tavg_data = []\n", "    tavg_time = []\n", "    eeg_data = []\n", "    eeg_time = []\n", "    for tavg, eeg in sim(simulation_length=2 ** 12):\n", "    # approx 4 sec\n", "        if not tavg is None:\n", "            tavg_time.append(tavg[0])\n", "            tavg_data.append(tavg[1])\n", "        if not eeg is None:\n", "            eeg_time.append(eeg[0])\n", "            eeg_data.append(eeg[1])\n", "    LOG.info(\"Finished simulation.\")\n", "    return tavg_data, tavg_time, eeg_data, eeg_time, sim.stimulus"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_stimulus(white_matter):\n", "    \"\"\"\n", "    Build a rectangular pulse train using an Equation datatype\n", "    \"\"\"\n\n", "    # access the region indices\n", "    white_matter.configure()\n\n", "    # specify weights for regions receiving stimulation  \n", "    weighting = numpy.zeros((white_matter.number_of_regions, 1))\n", "    weighting[nodes] = numpy.array([3.5, 0.0])[:, numpy.newaxis]\n", "    eqn_t = equations.PulseTrain()\n", "    eqn_t.parameters[\"onset\"] = 1000.0  # ms\n", "    eqn_t.parameters[\"tau\"] = 5.0    # ms\n", "    eqn_t.parameters[\"T\"] = 750.  # ms --> 0.0015kHz repetition frequency\n", "    stimulus = patterns.StimuliRegion(temporal=eqn_t, connectivity=white_matter, weight=weighting)\n", "    return stimulus"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_mse(xs_data, ys_data):\n", "    \"\"\"\n", "    Not trying to be smart. Only computing MSE for two different time series.\n", "    e.g\n", "    x: resting state eeg\n", "    y: evoked activity eeg\n", "    \"\"\"\n", "    from tvb.analyzers.info import sampen\n", "    x = numpy.array(xs_data)\n", "    y = numpy.array(ys_data)\n", "    sampen_x = sampen(x[2048:, 0, eeg_nodes[2], 0], r=.15, taus=numpy.r_[4:13], qse=False, m=2)\n", "    sampen_y = sampen(y[2048:, 0, eeg_nodes[2], 0], r=.15, taus=numpy.r_[4:13], qse=False, m=2)\n", "    return sampen_x, sampen_y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_data(tavg_data, eeg_data, tavg_time, eeg_time, stimulus=None):\n", "    \"\"\"\n", "    Save simulated data\n", "    \"\"\"\n", "    TAVG = numpy.array(tavg_data)\n", "    EEG = numpy.array(eeg_data)\n", "    if stimulus is None:\n", "        FILE_NAME = \"rs_tavg_data_region_4s_2048Hz.npy\"\n", "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "        numpy.save(FILE_NAME, TAVG)\n", "        FILE_NAME = \"rs_eeg_data_region_4s_2048Hz.npy\"\n", "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "        numpy.save(FILE_NAME, EEG)\n", "    else:\n", "        FILE_NAME = \"stim_eeg_data_region_4s_2048Hz.npy\"\n", "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "        numpy.save(FILE_NAME, EEG)\n", "        FILE_NAME = \"stim_tavg_data_region_4s_2048Hz.npy\"\n", "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "        numpy.save(FILE_NAME, TAVG)\n", "        FILE_NAME = \"stim_pattern_data_region_4s.npy\"\n", "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "        numpy.save(FILE_NAME, stimulus.temporal.pattern)\n", "    FILE_NAME = \"time_tavg_data_region_4s_2048Hz.npy\"\n", "    LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "    numpy.save(FILE_NAME, numpy.array(tavg_time))\n", "    FILE_NAME = \"time_eeg_data_region_4s_2048Hz.npy\"\n", "    LOG.info(\"Saving array to %s...\" % FILE_NAME)\n", "    numpy.save(FILE_NAME, numpy.array(eeg_time))\n\n", "    # I'm assuming both tavg and eeg time vectors have the tpts sampled at \n", "    # the same frequency."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_figure(se_x, se_y, eeg_data, tavg_data, rseeg, rstavg, pattern, nodes, eeg_nodes, time):\n", "    \"\"\"\n", "    Generate figure as shown in [1].\n", "    se_x: mse estimates for resting state like\n", "    se_y: mse estimates for evoked activity\n", "    eeg_data: evoked eeg\n", "    tavg_data: evoked raw data\n", "    rseeg: resting state eeg\n", "    rstavg: resting state raw\n", "    nodes:regions of interest\n", "    eeg_nodes: sensors of itnerest\n", "    time: time vector\n", "    \"\"\"\n", "    fig_width_pt = 1200.0  # Get this from LaTeX using \\showthe\\columnwidth\n", "    inches_per_pt = 1.0 / 72.27               # Convert pt to inch\n", "    golden_mean = (numpy.sqrt(5) + 1.0) / 2.0         # Aesthetic ratio\n", "    fig_width = fig_width_pt * inches_per_pt  # width in inches\n", "    fig_height = fig_width * golden_mean      # height in inches\n", "    fig_size = [fig_height, fig_width]\n", "    params = {'backend': 'ps',\n", "              'axes.labelsize': 26,\n", "              'text.fontsize': 20,\n", "              'legend.fontsize': 30,\n", "              'xtick.labelsize': 24,\n", "              'ytick.labelsize': 24,\n", "              'text.usetex': False,\n", "              'figure.figsize': fig_size}\n", "    pyplot.rcParams.update(params)\n", "    pyplot.locator_params(axis='y', nbins=4)\n\n", "    # assuming resting state time series\n", "    tavg_data = numpy.array(tavg_data)\n\n", "    # assuming evoked activity\n", "    eeg_data = numpy.array(eeg_data)\n\n", "    # subsample the stimulus\n", "    pattern = pattern[:, ::pattern.shape[1] / eeg_data.shape[0]].T\n", "    pattern = pattern[:-1, :]\n", "    plot_ts = True\n", "    if plot_ts:\n", "        figure(1)\n", "        # create a nice subplot layout\n", "        gs = gridspec.GridSpec(6, 4)\n", "        ax1 = subplot(gs[:2, :-1])\n", "        ax1z = subplot(gs[:2, -1])\n", "        ax0 = subplot(gs[2, :-1])\n", "        ax0z = subplot(gs[2, -1])\n", "        ax2 = subplot(gs[3:5, :-1])\n", "        ax2z = subplot(gs[3:5, -1])\n\n", "        # ER raw traces + stimulation pattern\n", "        temp_v2 = tavg_data[start:stop, 0, nodes[1], 0]\n", "        temp_v1 = tavg_data[start:stop, 0, nodes[0], 0]\n", "        temp_v1 = (temp_v1 - temp_v1.min())\n", "        temp_v2 = (temp_v2 - temp_v2.min())\n", "        temp_v1 /= abs(temp_v1.max())\n", "        temp_v2 /= abs(temp_v2.max())\n", "        temp_v2 *= 0.25\n", "        temp_v2 += temp_v1.max() + 0.5  # offset for pretty pictures\n\n", "        ## V2-V1 stochastic \n", "        ax1.plot(time[start:stop], temp_v2, color='#1C79FC', lw=3, label=\"V2\")\n", "        ax1.plot(time[start:stop], temp_v1, 'k', lw=3, label=\"V1\")\n", "        ax1.patch.set_facecolor('#1C79FC')\n", "        ax1.patch.set_alpha(0.15)\n", "        ax1.set_xlim([time[start], time[stop - 1]])\n", "        ax1.set_ylim([temp_v1.min() - 0.15, temp_v2.max() + 0.15])\n\n", "        ##  V2-V1 stochastic  - Zoom in \n", "        ax1z.plot(time[start:stop // 2], tavg_data[start:stop // 2, 0, nodes[1], 0], color='#1C79FC', lw=3, label=\"V2\")\n", "        ax1z.plot(time[start:stop // 2], tavg_data[start:stop // 2, 0, nodes[0], 0], 'k', lw=3, label=\"V1\")\n", "        ax1z.patch.set_facecolor('#1C79FC')\n", "        ax1z.patch.set_alpha(0.15)\n", "        ax1z.axes.get_xaxis().set_visible(False)\n", "        ax1z.set_xlabel(\"time (ms)\")\n", "        ax1.axes.get_xaxis().set_visible(False)\n", "        setp(ax1.get_yticklabels(), visible=False)\n", "        ax1.set_ylabel(\"raw traces\")\n", "        ax1.set_xlabel(\"time (ms)\")\n", "        ax1.legend()\n\n", "        ## pp\n\n", "        ## stimulus pattern\n", "        ax0.plot(time[start:stop], pattern[start:stop], 'r', linewidth=3, alpha=0.4, label=\"stim\")\n", "        ax0.set_xlim([time[start], time[stop - 1]])\n", "        ax0.axes.get_xaxis().set_visible(False)\n", "        ax0.set_ylim([-0.1, 1.25])\n", "        setp(ax0.get_yticklabels(), visible=False)\n", "        ax0.set_ylabel(\"stimulus\")\n\n", "        ##  Stimulus pattern  - Zoom in \n", "        ax0z.plot(time[start:stop // 2], 3.5 * pattern[start:stop // 2], 'r', linewidth=3, alpha=0.4, label=\"stim\")\n", "        ax0z.axes.get_xaxis().set_visible(False)\n", "        ax0z.set_ylim([-0.1, 3.75])\n\n", "        # eeg traces\n", "        temp_oz = eeg_data[start:stop, 0, eeg_nodes[2], 0]\n", "        temp_o1 = eeg_data[start:stop, 0, eeg_nodes[0], 0]\n", "        temp_oz = (temp_oz - temp_oz.min())\n", "        temp_o1 = (temp_o1 - temp_o1.min())\n", "        temp_oz += temp_o1.max()\n", "        ax2.plot(time[start:stop], temp_oz, 'k', lw=2, label=\"OZ\")\n", "        ax2.plot(time[start:stop], temp_o1, color='0.55', lw=2, label=\"O1\")\n", "        ax2.patch.set_facecolor('red')\n", "        ax2.patch.set_alpha(0.10)\n", "        ax2.set_xlim([time[start], time[stop - 1]])\n", "        ax2.set_ylim([temp_o1.min() - 0.15, temp_oz.max() + 0.15])\n", "        ax2.set_xlabel(\"time (ms)\")\n", "        setp(ax2.get_yticklabels(), visible=False)\n", "        ax2.set_ylabel(\"EEG \")\n", "        ax2.legend()\n\n", "        ## zoom in \n", "        ax2z.plot(time[start:stop // 2], eeg_data[start:stop // 2, 0, eeg_nodes[2], 0], 'k', lw=2, label=\"OZ\")\n", "        ax2z.plot(time[start:stop // 2], eeg_data[start:stop // 2, 0, eeg_nodes[0], 0], color='0.55', lw=2, label=\"O1\")\n", "        ax2z.patch.set_facecolor('red')\n", "        ax2z.patch.set_alpha(0.1)\n", "        ax2z.set_xticks([1000, 1100, 1200])\n", "        ax2z.set_xlabel(\"time (ms)\")\n", "        show()\n", "        #savefig(\"Fig11_sampen_sto.pdf\")\n", "    plot_sampen = True\n", "    if plot_sampen:\n", "        figure(2)\n", "        rseeg_data = numpy.array(rseeg)\n", "        gs = gridspec.GridSpec(3, 1)\n", "        ax0 = subplot(gs[0, :])\n", "        ax1 = subplot(gs[1, :])\n", "        ax2 = subplot(gs[2, :])\n", "        ax0.plot(time[start:stop], rseeg_data[start:stop, 0, eeg_nodes[2], 0], 'k', lw=2, label=\"OZ-RS\")\n", "        ax0.set_xlim([time[start], time[stop - 1]])\n", "        ax0.set_ylim([-25, 55])\n", "        ax0.axes.get_xaxis().set_visible(False)\n", "        ax0.patch.set_facecolor('green')\n", "        ax0.legend(loc=2)\n", "        ax0.patch.set_alpha(0.15)\n", "        pattern = (pattern * 8.) - 24.\n", "        ax1.plot(time[start:stop], eeg_data[start:stop, 0, eeg_nodes[2], 0], 'k', lw=2, label=\"OZ-ER\")\n", "        ax1.plot(time[start:stop], pattern[start:stop], 'k', linewidth=3, alpha=0.4, label=\"stim\")\n", "        ax1.set_xlim([time[start], time[stop]])\n", "        ax1.set_ylim([-25, 55])\n", "        ax1.set_xlabel(\"time [ms]\")\n", "        ax1.patch.set_facecolor('blue')\n", "        ax1.patch.set_alpha(0.15)\n", "        ax1.legend(loc=2)\n\n", "        # sample entropy\n", "        ax2.plot(numpy.r_[4:13], se_x, 'k--', label=\"resting state\", linewidth=3)\n", "        ax2.plot(numpy.r_[4:13], se_y, 'k', label=\"evoked activity\", linewidth=3)\n", "        ax2.set_xlim([4, 12])\n", "        ax2.set_ylabel(\"MSE\")\n", "        ax2.set_xlabel(\"temporal scale\")\n", "        ax2.legend(loc=2)\n", "        show()\n", "        #savefig(\"Fig12_mse.pdf\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[9]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    # First simulation --> resting state\n", "    sim = configure_simulation(stimulate=False)\n", "    ts, tt, es, et, _ = run_simulation(sim)\n\n", "    # Second simulation -- > evoked responses\n", "    sim_stim = configure_simulation(stimulate=True)\n", "    sts, stt, ses, sett, stim = run_simulation(sim_stim)\n", "    save_data(sts, ses, stt, sett, stim)\n\n", "    # Analyze --> compute sample entropy\n", "    se_x, se_y = compute_mse(es, ses)\n\n", "    # Visualize\n", "    pattern = stim.temporal.pattern\n", "    plot_figure(se_x, se_y, ses, sts, es, ts, pattern, nodes, eeg_nodes, et)\n", "    return LOG.info(\"\"\"Done.\"\"\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[10]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}